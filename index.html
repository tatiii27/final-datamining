<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Facebook Link Prediction - CSE 258 Assignment 2</title>
  <style>
    body {
      margin: 0;
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
      background: #f0f2f5;
      color: #050505;
    }

    .friends-page {
      display: flex;
      min-height: 100vh;
    }

    /*  sidebar */
    .sidebar {
      width: 260px;
      background: #ffffff;
      padding: 16px;
      box-sizing: border-box;
      border-right: 1px solid #3a3b3c;
      position: sticky;
      top: 0;
      height: 100vh;
      overflow-y: auto;
    }

    .sidebar h2 {
      margin: 0 0 16px;
      font-size: 22px;
      color: #1877f2;
    }

    .sidebar .project-info {
      padding: 12px;
      background: #f0f2f5;
      border-radius: 8px;
      margin-bottom: 16px;
      font-size: 13px;
    }

    .sidebar .project-info p {
      margin: 4px 0;
    }

    .sidebar nav a {
      display: block;
      padding: 10px 12px;
      margin-bottom: 4px;
      border-radius: 8px;
      color: #050505;
      text-decoration: none;
      font-size: 15px;
    }

    .sidebar nav a:hover {
      background: #e4e6eb;
    }

    .sidebar nav a.active {
      background: #1877f2;
      color: white;
      font-weight: 600;
    }

    /* main content  */
    .friends-main {
      flex: 1;
      padding: 24px;
      box-sizing: border-box;
      max-width: 1200px;
    }

    .friends-header {
      display: flex;
      justify-content: space-between;
      align-items: center;
      margin-bottom: 8px;
      padding-bottom: 16px;
      border-bottom: 1px solid #e4e6eb;
    }

    .friends-header h1 {
      margin: 0;
      font-size: 28px;
      color: #050505;
    }

    .subtitle {
      margin: 0 0 24px;
      font-size: 15px;
      color: #65676b;
      line-height: 1.5;
    }

    /* for content */
    .content-section {
      background: #ffffff;
      border-radius: 12px;
      padding: 20px;
      margin-bottom: 20px;
      box-shadow: 0 1px 2px rgba(0, 0, 0, 0.1);
    }

    .content-section h2 {
      margin: 0 0 16px;
      font-size: 20px;
      color: #1877f2;
      border-bottom: 2px solid #e4e6eb;
      padding-bottom: 8px;
    }

    .content-section h3 {
      margin: 20px 0 12px;
      font-size: 16px;
      color: #1877f2;
    }

    .content-section p {
      line-height: 1.6;
      color: #050505;
      margin: 12px 0;
    }

    .content-section ul {
      padding-left: 20px;
      margin: 12px 0;
    }

    .content-section li {
      margin: 8px 0;
      color: #65676b;
    }

    /* code blocks */
    .code {
      background: #f0f2f5;
      border: 1px solid #e4e6eb;
      border-radius: 8px;
      padding: 16px;
      font-family: 'Courier New', monospace;
      font-size: 13px;
      color: #050505;
      overflow-x: auto;
      margin: 16px 0;
    }

    /* stats grid */
    .stats-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 16px;
      margin: 20px 0;
    }

    .stat-card {
      background: #f0f2f5;
      padding: 16px;
      border-radius: 8px;
      text-align: center;
      border: 1px solid #1877f2;
    }

    .stat-card .number {
      font-size: 24px;
      font-weight: bold;
      color: #1877f2;
    }

    .stat-card .label {
      font-size: 13px;
      color: #65676b;
      margin-top: 4px;
    }

    /* feature pills */
    .pill-row {
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
      margin: 16px 0;
    }

    .pill {
      background: #ffffff;
      padding: 6px 12px;
      border-radius: 20px;
      font-size: 13px;
      color: #050505;
      border: 2px solid #1877f2;
    }

    /* results table */
    table {
      width: 100%;
      border-collapse: collapse;
      margin: 16px 0;
    }

    th {
      background: #e4e6eb;
      padding: 10px;
      text-align: left;
      color: #050505;
      font-weight: 600;
    }

    td {
      padding: 10px;
      border-bottom: 1px solid #e4e6eb;
      color: #050505;
    }

    tr.highlight {
      background: #e7f3ff;
    }

    /* images */
    .plot-placeholder {
      background: #f0f2f5;
      padding: 40px;
      text-align: center;
      border-radius: 8px;
      margin: 16px 0;
      color: #65676b;
      font-style: italic;
      border: 1px solid #e4e6eb;
    }

    /* Key finding box */
    .key-finding {
      background: #e7f3ff;
      padding: 16px;
      border-radius: 8px;
      border-left: 4px solid #1877f2;
      margin: 16px 0;
    }

    .key-finding p:first-child {
      margin: 0;
      color: #1877f2;
      font-weight: bold;
      font-size: 16px;
    }

    /* smooth scroll */
    html {
      scroll-behavior: smooth;
    }

    /* responsive */
    @media (max-width: 768px) {
      .friends-page {
        flex-direction: column;
      }
      
      .sidebar {
        width: 100%;
        height: auto;
        position: static;
      }
      
      .stats-grid {
        grid-template-columns: 1fr;
      }
    }
  </style>
</head>

<body>
  <div class="friends-page">
    <aside class="sidebar">
      <h2>Link Prediction</h2>
      
      <div class="project-info">
        <p><strong>CSE 258</strong></p>
        <p>Assignment 2</p>
        <p>Fall 2024</p>
      </div>

      <nav>
        <a href="#task" class="active">Task Definition</a>
        <a href="#eda">Data Analysis</a>
        <a href="#features">Features</a>
        <a href="#models">Models</a>
        <a href="#results">Results</a>
        <a href="#discussion">Discussion</a>
        <a href="#references">References</a>
      </nav>

      <div class="project-info" style="margin-top: 20px;">
        <p><strong>Team Members:</strong></p>
        <p>• Shaily Nieves Adame</p>
        <p>• Tatianna Sanchez</p>
      </div>
    </aside>

    <!-- main content -->
    <main class="friends-main">
      <div class="friends-header">
        <h1>Predicting Facebook Friendships</h1>
      </div>

      <p class="subtitle">
        Modeling how network structure in the Facebook friendship graph relates to the probability of future connections
        using collaborative filtering and machine learning techniques from CSE 258.
      </p>

      <!-- task section -->
      <div class="content-section" id="task">
        <h2>1. Predictive Task</h2>
        <p>
          The objective is to <strong>predict whether two Facebook users are friends</strong>
          based solely on the structure of the social network. This is framed as a supervised
          <strong>binary classification</strong> problem, also known as <strong>link prediction</strong>.
        </p>

        <h3>Problem Formulation</h3>
        <p>For each candidate pair of users (u, v), we predict:</p>
        <div class="pill-row">
          <span class="pill">y = 1 → existing friendship (edge)</span>
          <span class="pill">y = 0 → non-edge (random sample)</span>
          <span class="pill">Binary Classification Task</span>
        </div>

        <h3>Input Features</h3>
        <ul>
          <li>Number of common friends (common neighbors)</li>
          <li>Jaccard similarity of friend sets</li>
          <li>Cosine similarity</li>
          <li>Correlation similarity (degree-based)</li>
        </ul>

        <h3>Evaluation Metrics</h3>
        <ul>
          <li><strong>ROC AUC</strong> - How well the model ranks true edges above non-edges</li>
          <li><strong>Average Precision (AP)</strong> - Summarizing the precision-recall curve</li>
          <li><strong>Accuracy</strong> - Classification correctness at 0.5 threshold</li>
        </ul>
      </div>

      <!-- EDA SECTION -->
      <div class="content-section" id="eda">
        <h2>2. Exploratory Data Analysis</h2>
        
        <h3>Facebook Network Statistics</h3>
        <div class="stats-grid">
          <div class="stat-card">
            <div class="number">4,039</div>
            <div class="label">Users (Nodes)</div>
          </div>
          <div class="stat-card">
            <div class="number">88,234</div>
            <div class="label">Friendships (Edges)</div>
          </div>
          <div class="stat-card">
            <div class="number">43.7</div>
            <div class="label">Mean Degree</div>
          </div>
          <div class="stat-card">
            <div class="number">0.011</div>
            <div class="label">Network Density</div>
          </div>
        </div>

        <h3>Degree Distribution Analysis</h3>
        <p>
          The network exhibits <strong>scale-free</strong> behavior with a power law degree distribution.
          The degree distribution is heavily right-skewed with mean (43.7) > median (23.0), indicating
          a long tail of high-degree hubs.
        </p>
        
        <div class="stats-grid">
          <div class="stat-card">
            <div class="number">2.09</div>
            <div class="label">Power Law Exponent (γ)</div>
          </div>
          <div class="stat-card">
            <div class="number">0.866</div>
            <div class="label">R² (Log-Log Fit)</div>
          </div>
          <div class="stat-card">
            <div class="number">1,045</div>
            <div class="label">Max Degree</div>
          </div>
          <div class="stat-card">
            <div class="number">1</div>
            <div class="label">Min Degree</div>
          </div>
        </div>

        <div class="plot-placeholder">
          <img src="Degree Dist (Linear).png" alt="Degree distribution on linear scale"
            class="plot-img">
          
          <img src="Degree Dist (Log-Log scale).png" alt="Degree distribution on log-log scale"
            class="plot-img">
          
          <img src="Clustering Distribution.png" alt="Clustering coefficient distribution"
            class="plot-img">
        </div>

        <h3>Clustering & Small-World Properties</h3>
        <div class="stats-grid">
          <div class="stat-card">
            <div class="number">0.606</div>
            <div class="label">Mean Clustering</div>
          </div>
          <div class="stat-card">
            <div class="number">0.620</div>
            <div class="label">Median Clustering</div>
          </div>
        </div>

        <p>
          High clustering coefficient (~0.606) indicates that a user's friends often know each other,
          confirming strong <strong>triadic closure</strong> - the key mechanism for friend recommendations.
        </p>

        <h3>Clustering by Degree Bins</h3>
        <table>
          <tr>
            <th>Degree Range</th>
            <th>Average Clustering</th>
          </tr>
          <tr>
            <td>1-10</td>
            <td>0.5531</td>
          </tr>
          <tr>
            <td>11-20</td>
            <td>0.5336</td>
          </tr>
          <tr>
            <td>21-50</td>
            <td>0.5722</td>
          </tr>
          <tr>
            <td>51-100</td>
            <td>0.6072</td>
          </tr>
          <tr>
            <td>101-200</td>
            <td>0.6493</td>
          </tr>
          <tr>
            <td>200+</td>
            <td>0.6461</td>
          </tr>
        </table>
      </div>

      <!-- features section -->
      <div class="content-section" id="features">
        <h2>3. Feature Engineering</h2>
        
        <h3>Structural Similarity Features</h3>
        <div class="code">
# For each pair (u, v):
Γ(u) = set of neighbors of u
Γ(v) = set of neighbors of v

1. Common Neighbors = |Γ(u) ∩ Γ(v)|
2. Jaccard = |Γ(u) ∩ Γ(v)| / |Γ(u) ∪ Γ(v)|
3. Cosine = |Γ(u) ∩ Γ(v)| / √(|Γ(u)| × |Γ(v)|)
4. Correlation_similarity = |Γ(u) ∩ Γ(v)| / √((|Γ(u)| - 1) × (|Γ(v)| - 1))
        </div>

        <h3>Dataset Construction</h3>
        <ul>
          <li><strong>Balanced Dataset:</strong> 20,000 positive + 20,000 negative examples</li>
          <li><strong>Positive examples:</strong> Existing edges (actual friendships)</li>
          <li><strong>Negative examples:</strong> Random non-edges sampled uniformly</li>
          <li><strong>Train-Test Split:</strong> 70/30 stratified split</li>
        </ul>

        <h3>Feature Vectors for Models</h3>
        <ul>
          <li><strong>Logistic Regression (Jaccard):</strong> Single feature [jaccard]</li>
          <li><strong>Logistic Regression (Full):</strong> [deg_u, deg_v, common_neighbors, jaccard]</li>
          <li><strong>Gradient Boosting:</strong> All 4 similarity metrics</li>
          <li><strong>SVD:</strong> 10-dimensional latent factors from adjacency matrix</li>
        </ul>
      </div>

      <!-- models section -->
      <div class="content-section" id="models">
        <h2>4. Models</h2>
        
        <h3>Baseline Models (From Course)</h3>
        <table>
          <tr>
            <th>Model</th>
            <th>Type</th>
            <th>Description</th>
            <th>Course Topic</th>
          </tr>
          <tr>
            <td>Logistic Regression (Jaccard)</td>
            <td>Classification</td>
            <td>Single similarity feature</td>
            <td>Week 3: Classification</td>
          </tr>
          <tr>
            <td>SVD/Matrix Factorization</td>
            <td>Latent Factors</td>
            <td>k=10 components, Netflix-style</td>
            <td>Week 5: Recommender Systems</td>
          </tr>
          <tr>
            <td>Common Neighbors</td>
            <td>Heuristic</td>
            <td>Pure collaborative filtering</td>
            <td>Week 4: Collaborative Filtering</td>
          </tr>
        </table>

        <h3>Advanced Models</h3>
        <table>
          <tr>
            <th>Model</th>
            <th>Type</th>
            <th>Features</th>
            <th>Parameters</th>
          </tr>
          <tr>
            <td>Logistic Regression (Full)</td>
            <td>Linear Model</td>
            <td>4 features</td>
            <td>max_iter=1000</td>
          </tr>
          <tr>
            <td>Gradient Boosting</td>
            <td>Ensemble</td>
            <td>4 similarity features</td>
            <td>n_estimators=100, max_depth=5</td>
          </tr>
        </table>
      </div>

      <!-- results section -->
      <div class="content-section" id="results">
        <h2>5. Results</h2>
        
        <h3>Model Performance Comparison</h3>
        <table>
          <tr>
            <th>Model</th>
            <th>AUC</th>
            <th>Accuracy</th>
            <th>Average Precision</th>
          </tr>
          <tr>
            <td>Logistic Regression (Jaccard)</td>
            <td>0.990</td>
            <td>0.934</td>
            <td>0.989</td>
          </tr>
          <tr>
            <td>Logistic Regression (Full)</td>
            <td>0.993</td>
            <td>0.960</td>
            <td>0.991</td>
          </tr>
          <tr>
            <td>SVD/Matrix Factorization</td>
            <td>0.948</td>
            <td>0.867</td>
            <td>0.957</td>
          </tr>
          <tr class="highlight">
            <td><strong>Common Neighbors</strong></td>
            <td><strong>0.994</strong></td>
            <td>0.916</td>
            <td><strong>0.992</strong></td>
          </tr>
          <tr class="highlight">
            <td><strong>Gradient Boosting</strong></td>
            <td><strong>0.994</strong></td>
            <td><strong>0.970</strong></td>
            <td><strong>0.993</strong></td>
          </tr>
        </table>

        <div class="key-finding">
          <p>Key Finding: Simple Beats Complex!</p>
          <p>Common Neighbors achieves 0.994 AUC - matching Gradient Boosting's performance
          while requiring zero training time and offering perfect interpretability.</p>
        </div>

        <h3>Feature Importance (Gradient Boosting)</h3>
        <div class="stats-grid">
          <div class="stat-card">
            <div class="number">91.8%</div>
            <div class="label">Common Neighbors</div>
          </div>
          <div class="stat-card">
            <div class="number">2.2%</div>
            <div class="label">Jaccard</div>
          </div>
          <div class="stat-card">
            <div class="number">4.1%</div>
            <div class="label">Cosine</div>
          </div>
          <div class="stat-card">
            <div class="number">2.0%</div>
            <div class="label">Correlation</div>
          </div>
        </div>

        <p>
          Gradient Boosting's feature importance reveals that <strong>Common Neighbors contributes 91.8%</strong> 
          of the model's predictive power, explaining why the simple heuristic performs equally well.
        </p>

        <div class="plot-placeholder">
          <img src="model performance.png" alt="Model performance bar chart" class="plot-img">

        </div>

        <div class="plot-placeholder">
          <img src="ROC.png" alt="ROC curves for all models" class="plot-img">
        </div>

        <div class="plot-placeholder">
          <img src="PR.png" alt="Precision-Recall curves for all models" class="plot-img">
        </div>

        <div class="plot-placeholder">
          <img src="feature importance.png" alt="Feature importance from Gradient Boosting"
            class="plot-img">
        </div>
        
        <div class="plot-placeholder">
          <img src="performance summary.png" alt="Overall performance summary of all models"
            class="plot-img">
        </div>

        <h3>Complexity vs Performance Analysis</h3>
        <div class="plot-placeholder">
          <img src="complexity vs performance.png" alt="Model complexity versus performance"
          class="plot-img">
        </div>

        <p>
          The complexity analysis reveals that Common Neighbors sits at the optimal point:
          achieving maximum performance (0.994 AUC) with minimal complexity (no training, single feature).
        </p>
      </div>

      <!-- discussion section -->
      <div class="content-section" id="discussion">
        <h2>6. Discussion</h2>
        
        <h3>Main Findings</h3>
        <ul>
          <li>
            <strong>Simple Heuristic Wins:</strong> Common Neighbors (1960s concept) matches 
            state-of-the-art Gradient Boosting (2000s ML) with 0.994 AUC
          </li>
          <li>
            <strong>Triadic Closure Dominates:</strong> 91.8% of Gradient Boosting's predictive power 
            comes from counting mutual friends
          </li>
          <li>
            <strong>Latent Factors Underperform:</strong> SVD achieves only 0.948 AUC, showing that
            global patterns matter less than local structure in social networks
          </li>
          <li>
            <strong>Zero Training Required:</strong> Common Neighbors needs no model training, 
            enabling real-time predictions at scale
          </li>
        </ul>

        <h3>Why Simple Works for Facebook</h3>
        <p>
          The Facebook network's high clustering coefficient (0.606) and strong triadic closure
          mean that friendship formation is primarily driven by local structure. When your friends
          know each other (high clustering), the best predictor of new friendships is simply
          counting mutual connections.
        </p>

        <h3>Practical Implications</h3>
        <div class="pill-row">
          <span class="pill">10,000x faster inference than GB</span>
          <span class="pill">Perfect interpretability</span>
          <span class="pill">Scales to billions of users</span>
          <span class="pill">No retraining needed</span>
          <span class="pill">Real-time recommendations</span>
        </div>

        <h3>Model Trade-offs Summary</h3>
        <ul>
          <li><strong>Common Neighbors:</strong> Best for production - fast, simple, effective</li>
          <li><strong>Gradient Boosting:</strong> Marginally better accuracy (0.970 vs 0.916) but 
              complex and slow</li>
          <li><strong>Logistic Regression:</strong> Good balance of interpretability and performance</li>
          <li><strong>SVD:</strong> Poor fit for local friendship patterns, better for global structure</li>
        </ul>

        <h3>Limitations & Future Work</h3>
        <ul>
          <li>Static snapshot - could explore temporal dynamics of friendship formation</li>
          <li>Structure-only features - node attributes (age, location) could improve performance</li>
          <li>Single network - results may vary for LinkedIn, Twitter, or other social networks</li>
          <li>Balanced evaluation - real-world has many more non-edges than edges</li>
        </ul>
      </div>

      <!-- references section -->
      <div class="content-section" id="references">
        <h2>7. References</h2>
        <ul>
          <li>
            <strong>Liben-Nowell & Kleinberg (2007)</strong> - 
            The Link Prediction Problem for Social Networks. 
            <em>Introduced Common Neighbors and other heuristics used as our baselines.</em>
          </li>
          <li>
            <strong>McAuley & Leskovec (2012)</strong> - 
            Learning to Discover Social Circles in Ego Networks. 
            <em>Source of the Facebook dataset and analysis of network properties.</em>
          </li>
          <li>
            <strong>Watts & Strogatz (1998)</strong> - 
            Collective Dynamics of Small-World Networks. 
            <em>Theoretical foundation for high clustering and short paths observed.</em>
          </li>
          <li>
            <strong>Zhou, Lü & Zhang (2009)</strong> - 
            Predicting Missing Links via Local Information. 
            <em>Analysis showing why local methods outperform global in social networks.</em>
          </li>
          <li>
            <strong>CSE 258 Course Materials</strong> - 
            Classification (Week 3), Collaborative Filtering (Week 4), Recommender Systems (Week 5)
          </li>
        </ul>
      </div>

    </main>
  </div>
</body>
</html>